{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a convolutional neural network to predict promoter strength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules and define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tobia\\anaconda3\\envs\\CNN2.2\\lib\\site-packages\\ipykernel\\parentpoller.py:116: UserWarning: Parent poll failed.  If the frontend dies,\n",
      "                the kernel may be left running.  Please let us know\n",
      "                about your system (bitness, Python, etc.) at\n",
      "                ipython-dev@scipy.org\n",
      "  ipython-dev@scipy.org\"\"\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as k\n",
    "import tensorflow.keras.layers as kl\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "from io import TextIOBase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable GPU memory growth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to one-hot encode the DNA sequences (adapted from https://colab.research.google.com/drive/17E4h5aAOioh5DiTo7MZg4hpL6Z_0FyWr):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_encoder = LabelEncoder()  \n",
    "\n",
    "one_hot_encoder = OneHotEncoder(categories='auto')\n",
    "\n",
    "def one_hot_encoding(sequences, verbose = True): \n",
    "    one_hot_sequences = []\n",
    "\n",
    "    if verbose:\n",
    "        i = 0\n",
    "        print('one-hot encoding in progress ...', flush = True)\n",
    "    \n",
    "    for sequence in sequences:\n",
    "        integer_encoded = integer_encoder.fit_transform(list(sequence))\n",
    "        integer_encoded = np.array(integer_encoded).reshape(-1, 1)\n",
    "        one_hot_encoded = one_hot_encoder.fit_transform(integer_encoded)\n",
    "        one_hot_sequences.append(one_hot_encoded.toarray())\n",
    "    \n",
    "        if verbose:\n",
    "            i += 1\n",
    "            if i % 1000 == 0:\n",
    "                print(i, 'sequences processed', flush = True, end = '\\r')\n",
    "        \n",
    "    if verbose:\n",
    "        print('finished one-hot encoding:', i, 'sequences processed', flush = True)\n",
    "    \n",
    "    one_hot_sequences = np.stack(one_hot_sequences)\n",
    "\n",
    "    return one_hot_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a class to read in MEME files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Motif:\n",
    "    identifier: str\n",
    "    pfm: np.ndarray\n",
    "    alphabet_length: int\n",
    "    length: int\n",
    "    name: Optional[str] = None\n",
    "    source_sites: Optional[int] = None\n",
    "    source_evalue: Optional[float] = None\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.length\n",
    "    \n",
    "    \n",
    "class MinimalMEME:\n",
    "    \"\"\" http://meme-suite.org/doc/meme-format.html \"\"\"\n",
    "    \n",
    "    __version_regex = re.compile('^MEME version ([0-9]+)$')\n",
    "    __background_regex = re.compile('^Background letter frequencies(?: \\(from (.+)\\))?$')\n",
    "    __background_sum_error = 0.00001\n",
    "    __pfm_header_regex = re.compile('^letter-probability matrix:(?: alength= ([0-9]+))?(?: w= ([0-9]+))?(?: nsites= ([0-9]+))?(?: E= ([0-9.e-]+))?$')\n",
    "    version = None\n",
    "    alphabet = None\n",
    "    strands = None\n",
    "    background = None\n",
    "    background_source = None\n",
    "    motifs = None\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        self.motifs = {}\n",
    "        \n",
    "        # parse the minimal MEME file\n",
    "        with open(path) as minimal_meme_file:\n",
    "            line = minimal_meme_file.readline()\n",
    "            # first line must be version\n",
    "            self.version = self._parse_version(line)\n",
    "\n",
    "            line = minimal_meme_file.readline()\n",
    "            while line:\n",
    "                if line.startswith('ALPHABET'):\n",
    "                    if self.alphabet is None:\n",
    "                        self.alphabet = self._parse_alphabet(line)\n",
    "                        line = minimal_meme_file.readline()\n",
    "                    else:\n",
    "                        raise RuntimeError(\"Multiple alphabet definitions encountered in MEME file\")\n",
    "                elif line.startswith('strands: '):\n",
    "                    if self.strands is None:\n",
    "                        self.strands = self._parse_strands(line)\n",
    "                        line = minimal_meme_file.readline()\n",
    "                    else:\n",
    "                        raise RuntimeError(\"Multiple strand definitions encountered in MEME file\")\n",
    "                elif line.startswith('Background letter frequencies'):\n",
    "                    if self.background is None:\n",
    "                        line = self._parse_background(line, minimal_meme_file)\n",
    "                    else:\n",
    "                        raise RuntimeError(\"Multiple background frequency definitions encountered in MEME file\")\n",
    "                elif line.startswith('MOTIF'):\n",
    "                    line = self._parse_motif(line, minimal_meme_file)\n",
    "                else:\n",
    "                    line = minimal_meme_file.readline()\n",
    "    \n",
    "    def _parse_version(self, line: str) -> str:\n",
    "        match = re.match(self.__version_regex, line)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        else:\n",
    "            raise RuntimeError(\"Minimal MEME file missing version string on first line\")\n",
    "            \n",
    "    def _parse_alphabet(self, line: str) -> str:\n",
    "        if line.startswith('ALPHABET '):\n",
    "            raise NotImplementedError(\"Alphabet definitions not supported\")\n",
    "        elif line.startswith('ALPHABET= '):\n",
    "            return line.rstrip()[10:]\n",
    "        else:\n",
    "            raise RuntimeError('Unable to parse alphabet line')\n",
    "            \n",
    "    def _parse_strands(self, line: str) -> str:\n",
    "        strands = line.rstrip()[9:]\n",
    "        if not ((strands == '+') or (strands == '+ -')):\n",
    "            raise RuntimeError(\"Invalid strand specification\")\n",
    "        else:\n",
    "            return strands\n",
    "        \n",
    "    def _parse_background(self, line: str, handle: TextIOBase) -> str:\n",
    "        match = re.match(self.__background_regex, line)\n",
    "        if match:\n",
    "            if match.group(1) is not None:\n",
    "                self.background_source = match.group(1)\n",
    "        else:\n",
    "            raise RuntimeError(\"Unable to parse background frequency line\")\n",
    "\n",
    "        self.background = {}\n",
    "        # start parsing possibly multiple lines of background frequencies\n",
    "        line = handle.readline()\n",
    "        while line:\n",
    "            if (not line.rstrip()) or line.startswith('MOTIF'):\n",
    "                if abs(1 - sum(self.background.values())) <= self.__background_sum_error:\n",
    "                    return line\n",
    "                else:\n",
    "                    raise RuntimeError(\"Background frequencies do not sum to 1\")\n",
    "            else:\n",
    "                line_freqs = line.rstrip().split(' ')\n",
    "                if len(line_freqs) % 2 != 0:\n",
    "                    raise RuntimeError(\"Invalid background frequency definition\")\n",
    "                for residue, freq in zip(line_freqs[0::2], line_freqs[1::2]):\n",
    "                    self.background[residue] = float(freq)\n",
    "            line = handle.readline()\n",
    "    \n",
    "    def _parse_motif(self, line: str, handle: TextIOBase) -> str:\n",
    "        # parse motif identifier\n",
    "        line_split = line.rstrip().split(' ')\n",
    "        if (len(line_split) < 2) or (len(line_split) > 3):\n",
    "            raise RuntimeError(\"Invalid motif name line\")\n",
    "        motif_identifier = line_split[1]\n",
    "        motif_name = line_split[2] if len(line_split) == 3 else None\n",
    "        \n",
    "        line = handle.readline()\n",
    "        # parse letter probability matrix header\n",
    "        if not line.startswith('letter-probability matrix:'):\n",
    "            raise RuntimeError(\"No letter-probability matrix header line in motif entry\")\n",
    "        match = re.match(self.__pfm_header_regex, line)\n",
    "        if match:\n",
    "            motif_alphabet_length = int(match.group(1)) if match.group(1) is not None else None\n",
    "            motif_length = int(match.group(2)) if match.group(2) is not None else None\n",
    "            motif_source_sites = int(match.group(3)) if match.group(3) is not None else None\n",
    "            motif_source_evalue = float(match.group(4)) if match.group(4) is not None else None\n",
    "        else:\n",
    "            raise RuntimeError(\"Unable to parse letter-probability matrix header\")\n",
    "        \n",
    "        # parse letter probability matrix\n",
    "        line = handle.readline()\n",
    "        pfm_rows = []\n",
    "        while line:\n",
    "            if (not line.rstrip()) or line.startswith('MOTIF'):\n",
    "                if motif_identifier in self.motifs:\n",
    "                    raise RuntimeError(\"Motif identifiers not unique within file\")\n",
    "                pfm = np.stack(pfm_rows)\n",
    "                if motif_length is None:\n",
    "                    motif_length = pfm.shape[0]\n",
    "                elif motif_length != pfm.shape[0]:\n",
    "                    raise RuntimeError(\"Provided motif length is not consistent with the letter-probability matrix shape\")\n",
    "                self.motifs[motif_identifier] = Motif(\n",
    "                    identifier = motif_identifier,\n",
    "                    pfm = pfm,\n",
    "                    alphabet_length = motif_alphabet_length,\n",
    "                    length = motif_length,\n",
    "                    name = motif_name,\n",
    "                    source_sites = motif_source_sites,\n",
    "                    source_evalue = motif_source_evalue\n",
    "                )\n",
    "                return line\n",
    "            else:\n",
    "                line_split = line.rstrip().split()\n",
    "                if motif_alphabet_length is None:\n",
    "                    motif_alphabet_length = len(line_split)\n",
    "                elif motif_alphabet_length != len(line_split):\n",
    "                    raise RuntimeError(\"Letter-probability matrix row length doesn't equal alphabet length\")\n",
    "                pfm_row = np.array([float(s) for s in line_split])\n",
    "                pfm_rows.append(pfm_row)\n",
    "                line = handle.readline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and convert the data to the required format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load CPE and TF motifs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_promoter_elements = MinimalMEME('../data/misc/CPEs.meme')\n",
    "tf_groups = MinimalMEME('../data/misc/TF-clusters.meme')\n",
    "all_motifs = {**core_promoter_elements.motifs, **tf_groups.motifs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_leaf = pd.read_csv('CNN_test_leaf.tsv', sep = '\\t', header = 0)\n",
    "data_train_leaf = pd.read_csv('CNN_train_leaf.tsv', sep = '\\t', header = 0)\n",
    "data_test_proto = pd.read_csv('CNN_test_proto.tsv', sep = '\\t', header = 0)\n",
    "data_train_proto = pd.read_csv('CNN_train_proto.tsv', sep = '\\t', header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encode the promoter sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one-hot encoding in progress ...\n",
      "finished one-hot encoding: 65004 sequences processed\n",
      "one-hot encoding in progress ...\n",
      "finished one-hot encoding: 7154 sequences processed\n",
      "one-hot encoding in progress ...\n",
      "finished one-hot encoding: 68213 sequences processed\n",
      "one-hot encoding in progress ...\n",
      "finished one-hot encoding: 7595 sequences processed\n"
     ]
    }
   ],
   "source": [
    "train_sequences_leaf = one_hot_encoding(data_train_leaf['sequence'])\n",
    "test_sequences_leaf = one_hot_encoding(data_test_leaf['sequence'])\n",
    "train_sequences_proto = one_hot_encoding(data_train_proto['sequence'])\n",
    "test_sequences_proto = one_hot_encoding(data_test_proto['sequence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the enrichment value to an array of the correct shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_enrichment_leaf = np.array(data_train_leaf['enrichment']).reshape(-1, 1)\n",
    "test_enrichment_leaf = np.array(data_test_leaf['enrichment']).reshape(-1, 1)\n",
    "train_enrichment_proto = np.array(data_train_proto['enrichment']).reshape(-1, 1)\n",
    "test_enrichment_proto = np.array(data_test_proto['enrichment']).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a bidirectional convolutional layer stack, inspired from DeepGMAP (https://doi.org/10.1371/journal.pone.0235748)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiConv1D(kl.Layer):\n",
    "    def __init__(self, filters, kernel_size, layers = 2, stride = 1, dropout_rate = 0.15):\n",
    "        super().__init__()\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        if layers < 1:\n",
    "            raise ValueError(\"At least one layer needed\")\n",
    "        self.layers = layers\n",
    "        if (dropout_rate < 0) or (dropout_rate > 1):\n",
    "            raise ValueError(\"Dropout rate must be a float between 0 and 1\")\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.stride = stride\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.kernels = []\n",
    "        self.biases = []\n",
    "        for layer in range(self.layers):\n",
    "            self.kernels.append(self.add_weight(\n",
    "                f\"kernel{layer}\",\n",
    "                shape = (self.kernel_size, input_shape[-1], self.filters),\n",
    "                trainable = True,\n",
    "                initializer = k.initializers.GlorotUniform()\n",
    "            ))\n",
    "            self.biases.append(self.add_weight(\n",
    "                f\"bias{layer}\",\n",
    "                shape = (self.filters,),\n",
    "                trainable = True,\n",
    "                initializer = k.initializers.Zeros()\n",
    "            ))\n",
    "\n",
    "    def call(self, input):\n",
    "        # first layer\n",
    "        x_fwd = tf.nn.conv1d(input, self.kernels[0], stride = self.stride, padding = 'SAME')\n",
    "        x_fwd = tf.add(x_fwd, self.biases[0])\n",
    "        x_fwd = tf.nn.dropout(tf.nn.relu(x_fwd), rate = self.dropout_rate)\n",
    "        x_rev = tf.nn.conv1d(input, tf.reverse(self.kernels[0], axis = [1, 2]), stride = self.stride, padding = 'SAME')\n",
    "        x_rev = tf.add(x_fwd, self.biases[0])\n",
    "        x_rev = tf.nn.dropout(tf.nn.relu(x_rev), rate = self.dropout_rate)\n",
    "        \n",
    "        # subsequent layers\n",
    "        for layer in range(1, self.layers):\n",
    "            x_fwd = tf.nn.conv1d(x_fwd, self.kernels[layer], stride = self.stride, padding = 'SAME')\n",
    "            x_fwd = tf.add(x_fwd, self.biases[layer])\n",
    "            x_fwd = tf.nn.dropout(tf.nn.relu(x_fwd), rate = self.dropout_rate)\n",
    "            x_rev = tf.nn.conv1d(x_rev, tf.reverse(self.kernels[layer], axis = [1, 2]), stride = self.stride, padding = 'SAME')\n",
    "            x_rev = tf.add(x_fwd, self.biases[layer])\n",
    "            x_rev = tf.nn.dropout(tf.nn.relu(x_rev), rate = self.dropout_rate)\n",
    "        \n",
    "        return tf.math.add(x_fwd, x_rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to build the bidirectional model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bidirectional_model(motif_kernel: np.ndarray):\n",
    "    # motif_kernel.shape[2] is filters, shape[0] is kernel size\n",
    "    inputs = kl.Input((170, 4))\n",
    "    x = BiConv1D(filters = motif_kernel.shape[2], kernel_size = motif_kernel.shape[0], layers = 2)(inputs)\n",
    "    x = kl.Conv1D(filters = 128, kernel_size = 13, padding = 'same', activation = 'relu')(x)\n",
    "    x = kl.Dropout(0.15)(x)\n",
    "    x = kl.Flatten()(x)\n",
    "    x = kl.Dense(64)(x)\n",
    "    x = kl.BatchNormalization()(x)\n",
    "    x = kl.Activation('relu')(x)\n",
    "    outputs = kl.Dense(1)(x)\n",
    "    model = k.Model(inputs = inputs, outputs = outputs, name = \"BiDirectionalCNN\")\n",
    "    # initialize first layer kernel with motifs\n",
    "    model.layers[1].kernels[0].assign(motif_kernel)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the kernal weights with CPE and TF motifs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = k.initializers.GlorotUniform()(shape = (13, 4, 128)).numpy()\n",
    "\n",
    "# overwrite part of kernel with pfms from motifs\n",
    "for i, motif_id in enumerate(all_motifs):\n",
    "    motif = all_motifs[motif_id]\n",
    "    \n",
    "    # convert PFM to PWM, assume equal background frequency of 0.25\n",
    "    # truncates motifs longer than 13bp to 13bp\n",
    "    kernel[:min(len(motif), kernel.shape[0]), :, i] = motif.pfm[:min(len(motif), kernel.shape[0]), :] / 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and compile the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method BiConv1D.call of <__main__.BiConv1D object at 0x0000016EDD97FB88>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method BiConv1D.call of <__main__.BiConv1D object at 0x0000016EDD97FB88>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "model_leaf = build_bidirectional_model(kernel)\n",
    "model_proto = build_bidirectional_model(kernel)\n",
    "\n",
    "model_leaf.compile(\n",
    "    loss = 'mean_squared_error',\n",
    "    optimizer = 'Adam',\n",
    "    metrics = ['mean_squared_error']\n",
    ")\n",
    "model_proto.compile(\n",
    "    loss = 'mean_squared_error',\n",
    "    optimizer = 'Adam',\n",
    "    metrics = ['mean_squared_error']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define training parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStop = k.callbacks.EarlyStopping(patience = 5)\n",
    "reduceLR = k.callbacks.ReduceLROnPlateau(patience = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model for the tobacco leaf system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir('model_leaf'):\n",
    "    # load previously trained model\n",
    "    model_leaf = k.models.load_model('model_leaf')\n",
    "else:\n",
    "    # train model\n",
    "    model_leaf.fit(\n",
    "        train_sequences_leaf,\n",
    "        train_enrichment_leaf, \n",
    "        epochs = 25,\n",
    "        batch_size = 128,\n",
    "        validation_split = 0.1,\n",
    "        callbacks = [earlyStop, reduceLR],\n",
    "        verbose = 1\n",
    "    )\n",
    "\n",
    "    # save model\n",
    "    model_leaf.save('model_leaf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model for the maize protoplast system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir('model_proto'):\n",
    "    # load previously trained model\n",
    "    model_proto = k.models.load_model('model_proto')\n",
    "else:\n",
    "    # train model\n",
    "    model_proto.fit(\n",
    "        train_sequences_proto,\n",
    "        train_enrichment_proto, \n",
    "        epochs = 25,\n",
    "        batch_size = 128,\n",
    "        validation_split = 0.1,\n",
    "        callbacks = [earlyStop, reduceLR],\n",
    "        verbose = 1\n",
    "    )\n",
    "\n",
    "    # save model\n",
    "    model_proto.save('model_proto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalutate the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict enrichment for the training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000016EC1F7CDC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000016EC1F7CDC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000016EC206C948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000016EC206C948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "predicted_enrichment_train_leaf = model_leaf.predict(np.stack(train_sequences_leaf))\n",
    "predicted_enrichment_test_leaf = model_leaf.predict(np.stack(test_sequences_leaf))\n",
    "predicted_enrichment_train_proto = model_proto.predict(np.stack(train_sequences_proto))\n",
    "predicted_enrichment_test_proto = model_proto.predict(np.stack(test_sequences_proto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add predicted values to the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_leaf['prediction'] = predicted_enrichment_test_leaf\n",
    "data_train_leaf['prediction'] = predicted_enrichment_train_leaf\n",
    "data_test_proto['prediction'] = predicted_enrichment_test_proto\n",
    "data_train_proto['prediction'] = predicted_enrichment_train_proto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename column with species identifier (for compatibility with LaTeX plotting code) and shuffle data to avoid one species always being drawn on top of another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_leaf = data_test_leaf.rename(columns = {'sp' : 'sample.name'}).sample(frac = 1)\n",
    "data_train_leaf = data_train_leaf.rename(columns = {'sp' : 'sample.name'}).sample(frac = 1)\n",
    "data_test_proto = data_test_proto.rename(columns = {'sp' : 'sample.name'}).sample(frac = 1)\n",
    "data_train_proto = data_train_proto.rename(columns = {'sp' : 'sample.name'}).sample(frac = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to calculate the correlation between the measured and predicted enrichment (overall and for each species individually):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cor(data):\n",
    "    samples = ['all', 'At', 'Zm', 'Sb']\n",
    "\n",
    "    rsquare = []\n",
    "    spearman = []\n",
    "\n",
    "    for species in samples:\n",
    "        if species == 'all':\n",
    "            data_filt = data\n",
    "        else:\n",
    "            data_filt = data[data['sample.name'] == species]\n",
    "        \n",
    "        rsquare.append(round(data_filt['enrichment'].corr(data_filt['prediction'])**2, 2))\n",
    "        spearman.append(round(data_filt['enrichment'].corr(data_filt['prediction'], method = 'spearman'), 2))\n",
    "\n",
    "    return pd.DataFrame({'sample.name' : samples, 'spearman' : spearman, 'rsquare' : rsquare})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate correlation for test and training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_test_leaf = get_cor(data_test_leaf)\n",
    "correlation_train_leaf = get_cor(data_train_leaf)\n",
    "correlation_test_proto = get_cor(data_test_proto)\n",
    "correlation_train_proto = get_cor(data_train_proto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how well the model performed on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data in tobacco leaf system:\n",
      "  sample.name  spearman  rsquare\n",
      "0         all      0.89     0.79\n",
      "1          At      0.81     0.69\n",
      "2          Zm      0.89     0.79\n",
      "3          Sb      0.89     0.79\n",
      "\n",
      "Test data in tobacco leaf system:\n",
      "  sample.name  spearman  rsquare\n",
      "0         all      0.84     0.71\n",
      "1          At      0.73     0.57\n",
      "2          Zm      0.86     0.73\n",
      "3          Sb      0.85     0.71\n",
      "\n",
      "Training data in maize protoplast system:\n",
      "  sample.name  spearman  rsquare\n",
      "0         all      0.86     0.77\n",
      "1          At      0.84     0.72\n",
      "2          Zm      0.86     0.76\n",
      "3          Sb      0.82     0.75\n",
      "\n",
      "Test data in maize protoplast system:\n",
      "  sample.name  spearman  rsquare\n",
      "0         all      0.79     0.67\n",
      "1          At      0.74     0.58\n",
      "2          Zm      0.81     0.69\n",
      "3          Sb      0.75     0.65\n"
     ]
    }
   ],
   "source": [
    "print('Training data in tobacco leaf system:')\n",
    "print(correlation_train_leaf)\n",
    "print('\\nTest data in tobacco leaf system:')\n",
    "print(correlation_test_leaf)\n",
    "print('\\nTraining data in maize protoplast system:')\n",
    "print(correlation_train_proto)\n",
    "print('\\nTest data in maize protoplast system:')\n",
    "print(correlation_test_proto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data to files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_leaf.to_csv('../figures/rawData/CNN_test_leaf_pred.tsv', sep = '\\t', index = False, columns = ['sample.name', 'enrichment', 'prediction'])\n",
    "data_test_proto.to_csv('../figures/rawData/CNN_test_proto_pred.tsv', sep = '\\t', index = False, columns = ['sample.name', 'enrichment', 'prediction'])\n",
    "# data_train_leaf.to_csv('../figures/rawData/CNN_train_leaf_pred.tsv', sep = '\\t', index = False, columns = ['sample.name', 'enrichment', 'prediction'])\n",
    "# data_train_proto.to_csv('../figures/rawData/CNN_train_proto_pred.tsv', sep = '\\t', index = False, columns = ['sample.name', 'enrichment', 'prediction'])\n",
    "\n",
    "correlation_test_leaf.to_csv('../figures/rawData/CNN_test_leaf_stats.tsv', sep = '\\t', index = False)\n",
    "correlation_test_proto.to_csv('../figures/rawData/CNN_test_proto_stats.tsv', sep = '\\t', index = False)\n",
    "# correlation_train_leaf.to_csv('../figures/rawData/CNN_train_leaf_stats.tsv', sep = '\\t', index = False)\n",
    "# correlation_train_proto.to_csv('../figures/rawData/CNN_train_proto_stats.tsv', sep = '\\t', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:CNN2.2]",
   "language": "python",
   "name": "conda-env-CNN2.2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
